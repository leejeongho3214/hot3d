{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import tarfile\n",
    "import os\n",
    "from dataset_api import Hot3dDataProvider\n",
    "from data_loaders.loader_object_library import load_object_library\n",
    "from data_loaders.mano_layer import MANOHandModel\n",
    "\n",
    "from projectaria_tools.core.stream_id import StreamId\n",
    "from data_loaders.headsets import Headset\n",
    "from projectaria_tools.core.calibration import FISHEYE624\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "stream_id = StreamId(\"214-1\")\n",
    "\n",
    "def get_gt(time_stamp, seq_name):\n",
    "    home = os.path.expanduser(\"~\")\n",
    "    hot3d_dataset_path = home + \"/Dataset/ljh/dataset/hot3d/full-hot3d\"\n",
    "\n",
    "    sequence_path = os.path.join(hot3d_dataset_path, seq_name)\n",
    "    \n",
    "    object_library_path = home +\"/Dataset/ljh/dataset/hot3d/assets\"\n",
    "    mano_hand_model_path = home + \"/dir/mano_v1_2/models\"\n",
    "\n",
    "    if not os.path.exists(sequence_path) or not os.path.exists(object_library_path):\n",
    "        print(\"Invalid input sequence or library path.\")\n",
    "        print(\"Please do update the path to VALID values for your system.\")\n",
    "        raise\n",
    "    object_library = load_object_library(object_library_folderpath=object_library_path)\n",
    "\n",
    "    mano_hand_model = None\n",
    "    if mano_hand_model_path is not None:\n",
    "        mano_hand_model = MANOHandModel(mano_hand_model_path)\n",
    "\n",
    "    hot3d_data_provider = Hot3dDataProvider(\n",
    "        sequence_folder=sequence_path,\n",
    "        object_library=object_library,\n",
    "        mano_hand_model=mano_hand_model,\n",
    "    )\n",
    "    \n",
    "    return hot3d_data_provider\n",
    "    \n",
    "root = \"/home/jeongho/Dataset/ljh/dataset/hot3d/clip_dataset/train_aria\"\n",
    "for tar_name in tqdm(os.listdir(root)):\n",
    "    root_path = os.path.join(root, tar_name)\n",
    "\n",
    "    # 초기 설정\n",
    "    video_path = os.path.join(\"/home/jeongho/Dataset/ljh/video/clip-hot3d\", tar_name.split(\".\")[0] + \".mp4\")\n",
    "    frame_size = None\n",
    "    fps = 30\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "\n",
    "    with tarfile.open(root_path, \"r:*\") as tar:\n",
    "        tar_list = tar.getnames()\n",
    "\n",
    "        time_stamp = (len(tar_list) - 1) // 8\n",
    "        for idx, time in enumerate(range(time_stamp)):\n",
    "            time = str(time).zfill(6)\n",
    "            \n",
    "            # 예시: 첫 번째 JSON 파일 읽기\n",
    "            json_member = tar.getmember(f\"{time}.info.json\")\n",
    "            json_content = tar.extractfile(json_member).read()\n",
    "            data = json.loads(json_content)\n",
    "\n",
    "            # 예시: 첫 번째 JPG 이미지 열기\n",
    "            jpg_member = tar.getmember(f\"{time}.image_214-1.jpg\")\n",
    "            img_data = tar.extractfile(jpg_member).read()\n",
    "            image = Image.open(io.BytesIO(img_data))\n",
    "            img = np.array(image)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            timestamp_ns, seq_name = data['ref_timestamp_ns'], data['sequence_id']\n",
    "            # Retrieve the image data for a given timestamp\n",
    "            \n",
    "            if not idx:\n",
    "                hot3d_data_provider = get_gt(timestamp_ns, seq_name)\n",
    "                device_data_provider = hot3d_data_provider.device_data_provider\n",
    "                frame_size = (img.shape[1], img.shape[0])  # (width, height)\n",
    "                out = cv2.VideoWriter(video_path, fourcc, fps, frame_size)\n",
    "            \n",
    "            aria_eye_gaze_data = (\n",
    "                device_data_provider.get_eye_gaze(timestamp_ns)\n",
    "                if hot3d_data_provider.get_device_type() is Headset.Aria\n",
    "                else None\n",
    "            )\n",
    "            \n",
    "            if aria_eye_gaze_data is not None:\n",
    "\n",
    "                # Reproject EyeGaze for raw images\n",
    "                camera_model = FISHEYE624\n",
    "                \n",
    "                eye_gaze_reprojection_data = (\n",
    "                    device_data_provider.get_eye_gaze_in_camera(\n",
    "                        stream_id, timestamp_ns, camera_model=camera_model\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                if (\n",
    "                    eye_gaze_reprojection_data is None\n",
    "                    or not eye_gaze_reprojection_data.any()\n",
    "                ):\n",
    "                    continue\n",
    "                \n",
    "            # Retrieve the image data for a given timestamp\n",
    "\n",
    "            cv2.circle(img = img, center = (int(eye_gaze_reprojection_data[0]), int(eye_gaze_reprojection_data[1])), radius= 10, color = (255, 255, 0), thickness=-1)\n",
    "            out.write(img)\n",
    "        out.release()\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ObjectLibrary' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m\n",
      "\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uid \u001b[38;5;129;01min\u001b[39;00m object_pose_collection\u001b[38;5;241m.\u001b[39mobject_uid_list:\n",
      "\u001b[1;32m     48\u001b[0m     pose \u001b[38;5;241m=\u001b[39m object_pose_collection\u001b[38;5;241m.\u001b[39mposes[uid]\u001b[38;5;241m.\u001b[39mT_world_object\n",
      "\u001b[0;32m---> 49\u001b[0m     mesh \u001b[38;5;241m=\u001b[39m \u001b[43mobject_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(uid)  \u001b[38;5;66;03m# uid 기준으로 mesh 가져옴\u001b[39;00m\n",
      "\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mesh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ObjectLibrary' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Section 4: Eye Gaze data (only for Aria data)\n",
    "#\n",
    "# Take home message\n",
    "# - Eye Gaze data is only available for Aria sequences\n",
    "# - Eye Gaze data is retrieved via the device_data_provider\n",
    "# - Eye Gaze data is a 3D ray that can be reprojected at any desired depth in a given image\n",
    "#\n",
    "from tqdm import tqdm\n",
    "from projectaria_tools.core.stream_id import StreamId\n",
    "from data_loaders.headsets import Headset\n",
    "from projectaria_tools.core.calibration import FISHEYE624\n",
    "from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions\n",
    "\n",
    "\n",
    "device_data_provider = hot3d_data_provider.device_data_provider\n",
    "device_pose_provider = hot3d_data_provider.device_pose_data_provider\n",
    "stream_id = StreamId(\"214-1\")\n",
    "timestamps = device_data_provider.get_sequence_timestamps()\n",
    "object_pose_provider = hot3d_data_provider.object_pose_data_provider\n",
    "\n",
    "\n",
    "\n",
    "# Init a rerun context\n",
    "rr.init(\"Eye Gaze reprojection in RGB image\")\n",
    "rec = rr.memory_recording()\n",
    "\n",
    "# Limit to the some timestamps\n",
    "for timestamp_ns in tqdm(timestamps[:1000]):\n",
    "\n",
    "   # 1. OBJECTS\n",
    "    pose_with_dt = object_pose_provider.get_pose_at_timestamp(\n",
    "        timestamp_ns=timestamp_ns,\n",
    "        time_query_options=TimeQueryOptions.CLOSEST,\n",
    "        time_domain=TimeDomain.TIME_CODE\n",
    "    )\n",
    "    object_pose_collection = pose_with_dt.pose3d_collection\n",
    "\n",
    "    for uid in object_pose_collection.object_uid_list:\n",
    "        pose = object_pose_collection.poses[uid].T_world_object\n",
    "        mesh = object_library.get(uid)  # uid 기준으로 mesh 가져옴\n",
    "        if mesh is None:\n",
    "            continue\n",
    "\n",
    "        rr.log(\n",
    "            f\"mesh/object/{uid}\",\n",
    "            rr.Mesh3D(\n",
    "                vertex_positions=mesh.vertices,\n",
    "                indices=mesh.indices,\n",
    "                colors=mesh.vertex_colors,\n",
    "                transform=pose,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 2. HANDS (좌우 각각)\n",
    "    for hand_side in [\"left\", \"right\"]:\n",
    "        mano_pose3d = hot3d_data_provider.get_mano_hand_pose(timestamp_ns, hand_side)\n",
    "        if mano_pose3d is None:\n",
    "            continue\n",
    "        T_world_hand = mano_pose3d.T_world_hand\n",
    "        verts, faces = mano_hand_model.get_hand_mesh(hand_side, mano_pose3d.pose_params, mano_pose3d.shape_params)\n",
    "\n",
    "        rr.log(\n",
    "            f\"mesh/hand/{hand_side}\",\n",
    "            rr.Mesh3D(\n",
    "                vertex_positions=verts,\n",
    "                indices=faces,\n",
    "                colors=[(255, 255, 255)],  # 흰 손\n",
    "                transform=T_world_hand,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 3. GAZE VECTOR\n",
    "    camera_model = FISHEYE624\n",
    "    \n",
    "    eye_gaze_reprojection_data, gaze_center_in_camera = (\n",
    "        device_data_provider.get_eye_gaze_in_camera(\n",
    "            stream_id, timestamp_ns, camera_model=camera_model\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    T_world_camera = T_world_device @ extrinsics\n",
    "    gaze_center_in_world = T_world_camera @ gaze_center_in_camera\n",
    "\n",
    "    rr.log(\n",
    "        \"gaze/line\",\n",
    "        rr.Points3D(\n",
    "            positions=[gaze_center_in_world],\n",
    "            radii=0.04,\n",
    "            colors=[(0, 128, 255)],\n",
    "            labels=[uid],\n",
    "        )\n",
    "    )\n",
    "rr.notebook_show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hot3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
